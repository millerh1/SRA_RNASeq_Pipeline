#!/bin/bash

#### THE COMPLETE RNA SEQ PIPELINE FOR SRA INPUT READS *** also does Synapse too now *** ####

# Get the install directory
BIN_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
SCRIPT_DIR=$BIN_DIR/SRA_RNASeq_Pipeline_Files

function usage {
    echo
    echo "SRA_RNASeq_Pipeline [-a SRP_accession] [-p project_directory] [-t tests] [-g genome_directory] [-P num_threads] "
    echo
    echo "  -a|--SRP_accession     SRP       SRA study accession to download data from. [e.g. SRP045672]."
    echo "  -l|--SRA_list          file      File with newline-separated list of SRP, SRX, and/or SRR accessions."
    echo "  -p|--project_dir       dir       Name of project directory. [default = 'RNASeq_SRA_Pipeline_Project']"
    echo "  -t|--tests             string    's' [salmon] 't' [TECount] 'S' [Splicing-STAR] 'f' [STAR-Fusion] Default: 'stSf'"
    echo "  -g|--genome_dir        dir       Name of genome directory. [default = package_dir/genome_build]"
    echo "  -P|--num_threads       int       Specify number of threads. [default = 1]"
    echo "  --python27_env         env       If 't' in tests, name of conda env with python 2.7 and TEtoolkit installed."
    echo "  --SF_env               env       Conda ENV with STAR-Fusion and STAR 2.7.0 [Due to conflict with 2.7.1]."
    echo "  --fastp                          Use fastp to perform adapter trimming, filtering, and fastq QC."
    echo "  --force_spliceSE                 Not recommended: If 'S' in tests, single-end reads are run with splicing STAR."
    echo "  --force_fusionSE                 Not recommended: If 'f' in tests, single-end reads are run with STAR-fusion."
    echo "  --synapseID            synID     Parent of desired file directory."
    echo "  --synapseIDList        file      File with newline-separated list of synpaseIDs (samples or sample folders)."               
    echo "  --username             string    Synapse username for downloading data (if --synapse is specified)."
    echo "  --help                           Display usage info"
    echo
    echo
    echo 
    echo "  EXAMPLES"
    echo 
    echo "  Running salmon and splicing STAR on runs listed in SRP045672 with fastp filtering/trimming:" 
    echo "  SRA_RNASeq_Pipeline -a SRP045672 -p sraTest/ -t sS -P 80 --fastp "
    echo
    echo "  Running all tests on a folder of fastq files identified by the synapse ID syn123456:"
    echo "  SRA_RNASeq_Pipeline -p synapseTest/ --synapseID=syn123456 --username=uName12 --python27_env=python27Env --SF_env=STAR270Env"
    echo
    exit 1
}



echo "Preparing and verifying inputs ... "

# Source conda
source $CONDA_PREFIX/etc/profile.d/conda.sh

# Argparse
while [ "$#" -gt 0 ]; do
  case "$1" in
    -a) ACC="$2"; shift 2;;
    -l) ACCLST="$2"; shift 2;;    
    -p) PROJECT_DIR="$2"; shift 2;;
    -t) TESTS="$2"; shift 2;;
    -g) GENOME_DIR_TOP="$2"; shift 2;;
    -P) THREADS="$2"; shift 2;;
    -c) CONDAENV="$2"; shift 2;;
    
    --SRP_accession=*) ACC="${1#*=}"; shift 1;;
    --SRA_list=*) ACCLST="${1#*=}"; shift 1;;        
    --project_dir=*) PROJECT_DIR="${1#*=}"; shift 1;;
    --tests=*) TESTS="${1#*=}"; shift 1;;
    --genome_dir=*) GENOME_DIR_TOP="${1#*=}"; shift 1;;
    --num_threads=*) THREADS="${1#*=}"; shift 1;;
    --python27_env=*) CONDAENV="${1#*=}"; shift 1;;
    --SF_env=*) STARENV="${1#*=}"; shift 1;;
    --force_spliceSE) FSS="${1#*=}"; shift 1;;
    --force_fusionSE) FSF="${1#*=}"; shift 1;;
    --fastp) FP="${1#*=}"; shift 1;;
    --synapseID=*) SYNID="${1#*=}"; shift 1;;
    --synapseIDList=*) SYNLST="${1#*=}"; shift 1;;         
    --username=*) USERR="${1#*=}"; shift 1;;
    --help) HELP="${1#*=}"; shift 1;;

    -*) echo "unknown option: $1" >&2; exit 1;;
    *) handle_argument "$1"; shift 1;;
  esac
done

# If specified, display usage info
if [ ! -z "$HELP" ]; then
  usage
  exit 1
fi

if [ ! -z "$SYNID" ]; then
  #SPECIES=${synapseSpecies:="human"} 
  if [ -z "$USERR" ]; then
    echo "ERROR: To run synapse, you must specify your synapse user name."
    usage
    exit 1
  fi
  # Read Password
  echo -n Password: 
  read -s PASS
  echo
elif [ -z "$ACC" ]; then
  if [ -z "$ACCLST" ]; then
    usage
    exit 1  
  fi
fi
if [ ! -z "$ACCLST" ]; then
    echo "Acquiring sample info will take longer with list input method depending on list size ... "
fi  

# Set defaults for variables not supplied

THREADS=${THREADS:=1}
ACCLST=${ACCLST:="none"}
ACC=${ACC:="none"}
TESTS=${TESTS:="stSf"}
GENOME_DIR_TOP=${GENOME_DIR_TOP:=$SCRIPT_DIR/genome_build}
if [ ! -d $GENOME_DIR_TOP ]; then
  echo "ERROR: Genome directory not found at "$GENOME_DIR_TOP" -- exiting"
  exit 1
fi

PROJECT_DIR=${PROJECT_DIR:=RNASeq_SRA_Pipeline_Project}
PROJECT_DIR=$(realpath $PROJECT_DIR)

if echo $TESTS | grep -q 't'; then
  if [ -z ${CONDAENV+x} ]; then
    echo "ERROR: To run TECount, user must supply name of a conda environment with python 2.7 and TEtoolkit installed."
    exit 1
  fi
fi

# Set working directory
if [ ! -d $PROJECT_DIR ]; then
  mkdir $PROJECT_DIR
fi
cd $PROJECT_DIR

# Create directory structure
(
mkdir Code
mkdir Data
mkdir Data/tmp
mkdir Data/Raw_Reads
mkdir Results
if [ ! -z $FP ]; then
  mkdir Data/QC
  mkdir Data/QC/HTML
  mkdir Data/QC/JSON
fi
if echo $TESTS | grep -q 'S'; then
  mkdir Data/Bam_Files
  mkdir Data/Bam_Files/Splicing_Bams
fi
if echo $TESTS | grep -q 't'; then
  mkdir Data/Bam_Files
  mkdir Data/Bam_Files/TE_Bams
  mkdir Results/TEcount.out
fi

if echo $TESTS | grep -q 's'; then
  mkdir Results/Salmon.out
fi
if echo $TESTS | grep -q 'f'; then
  mkdir Results/STAR-Fusion.out
fi

) &>/dev/null

if [ ! -z "$SYNID" ]; then
  SYNLST=${SYNLST:="none"}
  RUN_INFO=$(Rscript $SCRIPT_DIR/get_SYN_info.R $SYNID $SYNLST $SCRIPT_DIR)
  echo $RUN_INFO  
  fileType=$(Rscript $SCRIPT_DIR/checkExtension_Synapse.R $RUN_INFO)
  echo $fileType
else
  # Isolate the runList and convert to table
  RUN_INFO=$(Rscript $SCRIPT_DIR/get_SRA_info.R $ACC $ACCLST) # Get Runinfo table and save a copy in the code dir
fi
echo "Finished processing runInfo table... output stored in "$RUN_INFO # Prints success or failure message     
# Save a copy in the code dir
ACCNAME=$(basename $RUN_INFO .txt)
cat $RUN_INFO | tr -s '\t' ',' | csvcut -c Run > Code/$ACCNAME.accessionList.txt
LOGFILE=Code/$ACCNAME.pipeLineLog.txt
ACCLISTRUN=Code/$ACCNAME.accessionList.txt


### MAIN PIPELINE ###

#Output stderr to a log file
(
  echo "$(date "+%m%d%Y %T") : Starting main pipline ... "
  echo
  echo "Run info table for accessions is: "$RUN_INFO
  echo "Run access list is: "$ACCLISTRUN
  # This is needed for STAR later
  ulimit -n 10000   
    
  # While loop -- grabs SRA accession and/or file name and performs opperations
  while read line
  do
    if [ $line == "Run" ]; then
      continue
    fi
    
            
    ## DOWNLOAD READS AND MERGE MULTI-LANE FASTQS ##
    
    # R script to test for + merge technical replicates
    if [ -z $SYNID ]; then 
      echo
      echo "SRR Accession: "$line  
      SPECIES=$(Rscript $SCRIPT_DIR/getSpeciesSRA.R $line $RUN_INFO )
      if [ ! "$SPECIES" == "human" ] && [ ! "$SPECIES" == "mouse" ]; then
        echo "WARNING: species for " $line " is an unrecognized type: '"$SPECIES"'. Skipping this accession ... "
        continue
      fi
      echo "Detected species: "$SPECIES
      echo
      GENOME_DIR=$GENOME_DIR_TOP/$SPECIES
      if [ ! -d $GENOME_DIR ]; then
        echo "ERROR: $SPECIES genome subdir not found -- exiting"
        exit 1
      fi
      if [ ! -f Data/Raw_Reads/$line"_1.fastq" ] ; then
        techReps=$(Rscript $SCRIPT_DIR/techReps.R $line $RUN_INFO)
        if [ $techReps != "no" ]; then
          if [ $techReps == "skip" ]; then
            echo "Already merged siblings ... skipping"
            continue
          else
            echo "Technical replicates detected -- downloading and merging ..."
            # Create temporary download dir
            mkdir Data/tmp/toMerge
            # Download all the SRA accessions for files to be merged
            while read file
            do
              if [ $file != "V1" ]; then
                # Download file
                parallel-fastq-dump -t $THREADS -s $file --split-files -O Data/tmp/toMerge --tmpdir Data/tmp &>/dev/null
                # Cat first mate/SE reads
                cat Data/tmp/toMerge/$file"_1.fastq" >> Data/Raw_Reads/$line"_1.fastq"
                # Check to see if 2nd mate -- then merge if true
                if [ -f Data/tmp/toMerge/$file"_2.fastq" ]; then
                  cat Data/tmp/toMerge/$file"_2.fastq" >> Data/Raw_Reads/$line"_2.fastq"
                fi
              fi
            done < Data/tmp/sraTempTable.txt     
            wait
            if [ -f Data/tmp/sraTempTable.txt ]; then
              rm Data/tmp/sraTempTable.txt
            fi
            rm -rf Data/tmp/toMerge
          fi
        else
          echo "No technical replicates detected -- grabbing fastq reads from SRA ..."
          if [ ! -f Data/Raw_Reads/$line"_1.fastq" ]; then
            parallel-fastq-dump -t $THREADS -s $line --split-files -O Data/Raw_Reads --tmpdir Data/tmp &>/dev/null
            #fastq-dump -O Data/Raw_Reads --split-files $line
          fi
        fi
      else
        echo $line"_1.fastq already exists ... proceeding with pipeline ... "
      fi
    else 
      if [ $line == "synID" ]; then
        continue
      fi
      # Get species info
      echo
      echo "Synapse Accession: "$line  
      SPECIES=$(Rscript $SCRIPT_DIR/getSpeciesSYN.R $line $RUN_INFO )
      if [ ! "$SPECIES" == "human" ] && [ ! "$SPECIES" == "mouse" ]; then
        echo "WARNING: species for " $line " is an unrecognized type: '"$SPECIES"'. Skipping this accession ... "
        continue
      fi
      echo "Detected species: "$SPECIES
      echo
      GENOME_DIR=$GENOME_DIR_TOP/$SPECIES
      if [ ! -d $GENOME_DIR ]; then
        echo "ERROR: $SPECIES genome subdir not found -- exiting"
        exit 1
      fi

      
      synapse login -u $USERR -p $PASS --rememberMe
      mkdir Data/Raw_Reads/synDownloadTmp
      if [ $fileType == "fastq" ]; then
        echo "FASTQ file input ... "
        
        
        echo "Downloading fastq files and merging any technical replicates ... "
        techReps=$(Rscript $SCRIPT_DIR/techReps_Synapse.R $line $RUN_INFO) # Checks for pre-existing files internally
        
        if [ "$techReps" != "no" ]; then
          if [ "$techReps" == "skip" ]; then
            echo "Already merged siblings ... skipping"
            continue
          else
            synapseName=$(echo "$techReps")
            echo $synapseName
            echo "DONE"
          fi
        else
          echo "WARNING: Could not locate synapse ID in provided synapseMergeFile -- skipping"
          continue            
        fi
        
        rm -rf Data/Raw_Reads/synDownloadTmp
        
      elif [ $fileType == "bam" ]; then
        echo "BAM file input ... "
        synapse get $line --downloadLocation Data/Raw_Reads/synDownloadTmp/
        synapseName=$(ls Data/Raw_Reads/synDownloadTmp/)
        filename=$(basename -- "$synapseName")
        extension="${filename##*.}"
        synapseName=$(basename $synapseName .bam)
        if [ ! -f Data/Raw_Reads/$synapseName"_1.fastq" ]; then 
          echo "Checking if paired or single end ... "
          PETEST=$(samtools view -c -f 1 Data/Raw_Reads/synDownloadTmp/$synapseName.bam)
          COMP=2000
          if [ "$PETEST" -gt "$COMP" ]; then
            echo "Read is paired end!"
            mkdir Data/Raw_Reads/bamSortTmp
            echo "Sorting by read name ... "
            samtools sort -n -@ $THREADS -o Data/Raw_Reads/bamSortTmp/$synapseName.bam Data/Raw_Reads/synDownloadTmp/$synapseName.bam
            echo "DONE!"
            echo "Converting to fastq ..."
            bamToFastq -i Data/Raw_Reads/bamSortTmp/$synapseName.bam -fq Data/Raw_Reads/$synapseName"_1.fastq" -fq2 Data/Raw_Reads/$synapseName"_2.fastq" &>/dev/null 
            echo "DONE"
            echo "Removing old files ...  "
            rm -rf Data/Raw_Reads/synDownloadTmp
            rm -rf Data/Raw_Reads/bamSortTmp
            echo "DONE"        
          else
            echo "Reads is single end!"
            echo "Converting to fastq ..."
            bamToFastq -i Data/Raw_Reads/synDownloadTmp/$synapseName.bam -fq Data/Raw_Reads/$synapseName"_1.fastq" &>/dev/null 
            echo "DONE"
            echo "Removing old files ... "
            rm -rf Data/Raw_Reads/synDownloadTmp
            echo "DONE"        
          fi
        fi
      fi
      
      line=$synapseName
      echo $line      
      
    fi
    
    
    ## MAIN CODE ##
    
    # Testing single-end vs paired-end
    if [ -f Data/Raw_Reads/$line"_2.fastq" ]; then
      echo Paired End
      
      # Fastp
      if [ ! -z "$FP" ]; then
        echo "Running FASTP on reads ... "
        mv Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_1.fq"
        mv Data/Raw_Reads/$line"_2.fastq" Data/Raw_Reads/$line"_2.fq"
        fastp -i Data/Raw_Reads/$line"_1.fq" -o Data/Raw_Reads/$line"_1.fastq" -I Data/Raw_Reads/$line"_2.fq" -O Data/Raw_Reads/$line"_2.fastq" -h Data/QC/HTML/$line.html -j Data/QC/JSON/$line.json -w $THREADS
        rm Data/Raw_Reads/$line"_1.fq"
        rm Data/Raw_Reads/$line"_2.fq"
        echo "DONE"
      fi
      
      if echo $TESTS | grep -q 's'; then
        ## SALMON CODE ##
        echo "SALMON!"
        # Salmon quant -- for DGE and DTU
        salmon quant -i $GENOME_DIR/Salmon_Transcripts_Index -l A -1 Data/Raw_Reads/$line"_1.fastq" -2 Data/Raw_Reads/$line"_2.fastq" --validateMappings -o Results/Salmon.out/$line -p $THREADS --gcBias 
      fi
      
      if echo $TESTS | grep -q 't'; then
        ### TE COUNT CODE ###
        echo "TE COUNT!"
        # STAR  for TEcount
        mkdir Data/Bam_Files/TE_Bams/$line
        STAR --winAnchorMultimapNmax 100 --outFilterMultimapNmax 100 --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_2.fastq" --outFileNamePrefix Data/Bam_Files/TE_Bams/$line/Result 
        samtools view -b -@ $THREADS -o Data/Bam_Files/TE_Bams/$line/$line.bam Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        
        # R Script to get strandedness info
        # Don't forget this bit:
        # chmod +x Code/getStrandedInfo.R
        strand=$($SCRIPT_DIR/getStrandednessInfo.R $line)
        
        # Needs python2 for this
        source ~/miniconda3/etc/profile.d/conda.sh      
        conda activate $CONDAENV
        # TEcount
        TEcount --verbose 3 --stranded $strand --GTF $GENOME_DIR/Assembly_Files/Genes.gtf --TE $GENOME_DIR/Assembly_Files/TE.gtf -b Data/Bam_Files/TE_Bams/$line/$line.bam --project Results/TEcount.out/$line
        # deactivate environment
        conda deactivate
      
        # Remove old files
        rm Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        rm Data/Bam_Files/TE_Bams/$line/$line.bam
      fi
      
      if echo $TESTS | grep -q 'f'; then
        ## STAR FUSION CODE ##
        echo "STAR FUSION!"
        # Need to increase number of allowed threads or this will crash
        ulimit -n 10000
        if [ ! -z $STARENV ]; then
          echo "Activating conda 2.7.0 environment."
          conda activate $STARENV
        fi
        # Star fusion main command
        STAR-Fusion --left_fq Data/Raw_Reads/$line"_1.fastq" --right_fq Data/Raw_Reads/$line"_2.fastq" --genome_lib_dir $GENOME_DIR/ctat_genome_lib_build_dir/ --CPU $THREADS --output_dir Results/STAR-Fusion.out/$line --examine_coding_effect --FusionInspector inspect --FusionInspector validate --extract_fusion_reads
        echo "DONE"
        # Remove large old files
        echo "Cleaning up fusion files ... "
        find Results/STAR-Fusion.out/$line -type f -size +1G -exec rm -rf {} \;
        echo "DONE"
        if [ ! -z $STARENV ]; then
          conda deactivate
        fi
      fi
      
      if echo $TESTS | grep -q 'S'; then
        ### Splicing Bams CODE ###
        echo "SPLICING STAR!"
        # This code generates Bams for Splicing, QoRTS, and Leafcutter
        mkdir Data/Bam_Files/Splicing_Bams/$line
        # STAR for Splicing
        STAR --outSAMstrandField intronMotif --twopassMode Basic --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_2.fastq" --outFileNamePrefix Data/Bam_Files/Splicing_Bams/$line/Result
        
        # Sort output sam and convert to bam + index
        samtools view -b -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
        samtools sort -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam 
        # Index it both ways just incase...
        samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.bai
        samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam 
        
        # Remove old files 
        rm Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
        rm Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam
      fi
      
      rm Data/Raw_Reads/$line"_1.fastq"
      rm Data/Raw_Reads/$line"_2.fastq"
      
    else
      
      ## SINGLE END READ CODE ##
      echo Single End
      
      # Fastp
      if [ ! -z "$FP" ]; then
        echo "Running FASTP on reads ... "
        mv Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_1.fq"
        fastp -i Data/Raw_Reads/$line"_1.fq" -o Data/Raw_Reads/$line"_1.fastq" -h Data/QC/HTML/$line.html -j Data/QC/JSON/$line.json -w $THREADS
        rm Data/Raw_Reads/$line"_1.fq"
        echo "DONE"
      fi
      
      if echo $TESTS | grep -q 's'; then
        ## SALMON CODE ##
        echo "SALMON!"
        # Salmon quant -- for DGE and DTU
        salmon quant -i $GENOME_DIR/Salmon_Transcripts_Index -l A -r Data/Raw_Reads/$line"_1.fastq" --validateMappings -o Results/Salmon.out/$line -p $THREADS 
      fi
      
      if echo $TESTS | grep -q 't'; then      
        ### TE COUNT CODE ###
        echo "TE COUNT!"
        # STAR  for TEcount
        mkdir Data/Bam_Files/TE_Bams/$line
        STAR --winAnchorMultimapNmax 100 --outFilterMultimapNmax 100 --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" --outFileNamePrefix Data/Bam_Files/TE_Bams/$line/Result 
        samtools view -b -@ $THREADS -o Data/Bam_Files/TE_Bams/$line/$line.bam Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        
        # R Script to get strandedness info
        # Don't forget this bit:
        # chmod +x Code/getStrandedInfo.R
        strand=$($SCRIPT_DIR/getStrandednessInfo.R $line)
        
        # Needs python2 for this
        source ~/miniconda3/etc/profile.d/conda.sh
        conda activate $CONDAENV
        # TEcount
        TEcount --verbose 3 --stranded $strand --GTF $GENOME_DIR/Assembly_Files/Genes.gtf --TE $GENOME_DIR/Assembly_Files/TE.gtf -b Data/Bam_Files/TE_Bams/$line/$line.bam --project Results/TEcount.out/$line
        # Deactivate it
        conda deactivate
        
        # Remove old files
        rm Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        rm Data/Bam_Files/TE_Bams/$line/$line.bam
        
      fi
      
      if echo $TESTS | grep -q 'f'; then
        if [ ! -z "$FSF" ]; then
          ## STAR FUSION CODE ##
          echo "STAR FUSION!"
          # Need to increase number of allowed threads or this will crash
          ulimit -n 10000
          # Star fusion main command
          STAR-Fusion --left_fq Data/Raw_Reads/$line"_1.fastq" --genome_lib_dir $GENOME_DIR/ctat_genome_lib_build_dir/ --CPU $THREADS --output_dir Results/STAR-Fusion.out/$line --examine_coding_effect --FusionInspector inspect --FusionInspector validate --extract_fusion_reads
          echo "DONE"
          # Remove large old files
          echo "Cleaning up fusion files ... "
          find Results/STAR-Fusion.out/$line -type f -size +1G -exec rm -rf {} \;
          echo "DONE"
        else
          echo WARNING: STAR Fusion not run on single-end data. You can override this behavior by adding --force_fusionSE option.
        fi
      fi
      
      if echo $TESTS | grep -q 'S'; then
        if [ ! -z "$FSS" ]; then
          ### Splicing Bams CODE ###
          echo "SPLICING STAR!"
          # This code generates Bams for Splicing, QoRTS, and Leafcutter
          mkdir Data/Bam_Files/Splicing_Bams/$line
          # STAR for Splicing
          STAR --outSAMstrandField intronMotif --twopassMode Basic --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" --outFileNamePrefix Data/Bam_Files/Splicing_Bams/$line/Result
          
          # Sort output sam and convert to bam + index
          samtools view -b -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
          samtools sort -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam 
          # Index it both ways just incase...
          samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.bai
          samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam 
          
          # Remove old files 
          rm Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
          rm Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam

        else
          echo WARNING: Splicing STAR not run on single-end data. You can override this behavior by adding --force_spliceSE option.
        fi
      fi
      rm Data/Raw_Reads/$line"_1.fastq"
    fi
    
  done < $ACCLISTRUN
  wait
  
  echo "$(date "+%m%d%Y %T") : Done"
  
) |& tee $LOGFILE 


