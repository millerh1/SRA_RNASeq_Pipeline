#!/bin/bash

#### THE COMPLETE RNA SEQ PIPELINE FOR SRA INPUT READS *** also does Synapse too now *** ####

# Get the install directory
BIN_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
SCRIPT_DIR=$BIN_DIR/SRA_RNASeq_Pipeline_Files

function usage {
    echo
    echo "SRA_RNASeq_Pipeline [-a SRA_acc_list] [-s species] [-p project_directory] [-t tests] [-g genome_directory] [-P num_threads] "
    echo
    echo "  -a|--sra_acc_list        file      List of either srr or srx accessions in txt file - One accession per line."
    echo "  -s|--species             string    Select 'human' or 'mouse' [default = 'human']."
    echo "  -p|--project_directory   dir       Name of project directory. [default = 'RNASeq_SRA_Pipeline_Project']"
    echo "  -t|--tests               string    's' [salmon] 't' [TECount] 'S' [Splicing-STAR] 'f' [STAR-Fusion] Default: 'stSf'"
    echo "  -g|--genome_directory    dir       Name of genome directory. [default = package_dir/genome_build]"
    echo "  -P|--num_threads         int       Specify number of threads. [default = 1]"
    echo "  --python27_env           env       If 't' in tests, name of conda env with python 2.7 and TEtoolkit installed."
    echo "  --SF_env                 env       Conda ENV with STAR-Fusion and STAR 2.7.0 [Due to conflict with 2.7.1]."
    echo "  --fastp                            Use fastp to perform adapter trimming, filtering, and fastq QC."
    echo "  --force_spliceSE                   Not recommended: If 'S' in tests, single-end reads are run with splicing STAR."
    echo "  --force_fusionSE                   Not recommended: If 'f' in tests, single-end reads are run with STAR-fusion."
    echo "  --synapseID              synID     Parent of desired file directory."
    echo "  --synapseMergeFile       TSV file  Mapping from downloaded files to sample names [required for synapse fastqs]."                
    echo "  --username               string    Synapse username for downloading data (if --synapse is specified)."
    echo "  --help                             Display usage info"
    echo
    echo
    echo 
    echo "  EXAMPLES"
    echo 
    echo "  Running salmon and splicing STAR on a newline-separated list of SRA accessions with fastp filtering/trimming:" 
    echo "  SRA_RNASeq_Pipeline -a accList.txt -p sraTest/ -t sS -P 80 --fastp "
    echo
    echo "  Running all tests on a folder of mouse fastq files identified by the synapse ID syn123456:"
    echo "  SRA_RNASeq_Pipeline -s mouse -p synapseTest/ --synapse --synapseID=syn123456 --synapseMergeFile=synMerge.txt --username=uName12 --python27_env=python27Env --SF_env=STAR270Env"
    echo
    exit 1
}

# if less than one arguments supplied, display usage 
if [  $# -le 2 ] 
then 
	usage
	exit 1
fi 


# Source conda
source $CONDA_PREFIX/etc/profile.d/conda.sh

# Argparse
while [ "$#" -gt 0 ]; do
  case "$1" in
    -a) RUN_INFO="$2"; shift 2;;
    -s) SPECIES="$2"; shift 2;;
    -p) PROJECT_DIR="$2"; shift 2;;
    -t) TESTS="$2"; shift 2;;
    -g) GENOME_DIR="$2"; shift 2;;
    -P) THREADS="$2"; shift 2;;
    -c) CONDAENV="$2"; shift 2;;
    
    --sra_acc_list=*) RUN_INFO="${1#*=}"; shift 1;;
    --species=*) SPECIES="${1#*=}"; shift 1;;
    --project_directory=*) PROJECT_DIR="${1#*=}"; shift 1;;
    --tests=*) TESTS="${1#*=}"; shift 1;;
    --genome_directory=*) GENOME_DIR="${1#*=}"; shift 1;;
    --num_threads=*) THREADS="${1#*=}"; shift 1;;
    --conda_env=*) CONDAENV="${1#*=}"; shift 1;;
    --SF_env=*) STARENV="${1#*=}"; shift 1;;
    --force_spliceSE) FSS="${1#*=}"; shift 1;;
    --force_fusionSE) FSF="${1#*=}"; shift 1;;
    --fastp) FP="${1#*=}"; shift 1;;
    --synapseID=*) SYNID="${1#*=}"; shift 1;;
    --synapseMergeFile=*) synapseMergeFile="${1#*=}"; shift 1;;            
    --username=*) USERR="${1#*=}"; shift 1;;
    --help) HELP="${1#*=}"; shift 1;;

    -*) echo "unknown option: $1" >&2; exit 1;;
    *) handle_argument "$1"; shift 1;;
  esac
done

# If specified, display usage info
if [ ! -z "$HELP" ]; then
  usage
  exit 1
fi

if [ ! -z "$SYNID" ]; then
  echo $USERR
  if [ -z "$USERR" ]; then
    echo "ERROR: To run synapse, you must specify your synapse user name."
    usage
    exit 1
  fi
  # Read Password
  echo -n Password: 
  read -s PASS
  echo
    
fi


# Set defaults for variables not supplied
SPECIES=${SPECIES:="human"}
THREADS=${THREADS:=1}
TESTS=${TESTS:="stSf"}
GENOME_DIR=${GENOME_DIR:=$SCRIPT_DIR/genome_build}
if [ ! -d $GENOME_DIR ]; then
  echo "Genome dir not found -- exiting"
  exit 1
fi
GENOME_DIR=$GENOME_DIR/$SPECIES
if [ ! -d $GENOME_DIR ]; then
  echo "$SPECIES genome subdir not found -- exiting"
  exit 1
fi
PROJECT_DIR=${PROJECT_DIR:=RNASeq_SRA_Pipeline_Project}
PROJECT_DIR=$(realpath $PROJECT_DIR)

if echo $TESTS | grep -q 't'; then
  if [ -z ${CONDAENV+x} ]; then
    echo "To run TECount, user must supply name of a conda environment with python 2.7 and TEtoolkit installed."
    exit 1
  fi
fi
RIGHT_NOW=$(date +"%x %r %Z")
echo Beginning RNASeq SRA Pipeline at: $RIGHT_NOW

# Set working directory
if [ ! -d $PROJECT_DIR ]; then
  mkdir $PROJECT_DIR
fi
cd $PROJECT_DIR

# Create directory structure
(
mkdir Data
mkdir Data/Bam_Files
mkdir Data/Bam_Files/Splicing_Bams
mkdir Data/Bam_Files/TE_Bams
mkdir Data/Raw_Reads
mkdir Data/QC
mkdir Data/QC/HTML
mkdir Data/QC/JSON
mkdir Results
mkdir Results/Salmon.out
mkdir Results/TEcount.out
mkdir Results/STAR-Fusion.out
mkdir Code
mkdir Data/tmp
) &>/dev/null

if [ ! -z "$SYNID" ]; then
  # Get the synapse to filename mapping
  python $SCRIPT_DIR/getSynapse.py $SYNID $USERR $PASS Code/
  if [ ! -z "$synapseMergeFile" ]; then
    dos2unix $synapseMergeFile &>/dev/null
  fi
  fileType=$(Rscript $SCRIPT_DIR/checkExtension_Synapse.R)
  #cat $RUN_INFO > Code/runInfo_Table.txt 
  # Save a copy in the code dir
  RUN_INFO=Code/synapse.csv
  cat $RUN_INFO | tr -s '\t' ',' | csvcut -c synID > Code/Accession_List.txt
else
  # Clean input file since it originates from windows
  dos2unix $RUN_INFO &>/dev/null
  
  # Isolate the runList and convert to table
  $SCRIPT_DIR/get_srx_from_srr.R $RUN_INFO $PROJECT_DIR # Get SRR/SRX table and save a copy in the code dir
  
  #cat $RUN_INFO > Code/runInfo_Table.txt 
  # Save a copy in the code dir
  RUN_INFO=Code/runInfo_Table.txt
  cat $RUN_INFO | tr -s '\t' ',' | csvcut -c Run > Code/Accession_List.txt
fi



### MAIN PIPELINE ###

#Output stderr to a log file
LOGFILE=Code/pipeLineLog.txt

(
  echo "$(date "+%m%d%Y %T") : Starting work"
      
  # This is needed for STAR later
  ulimit -n 10000   
    
  # While loop -- grabs SRA accession and/or file name and performs opperations
  while read line
  do
    if [ $line == "Run" ]; then
      continue
    fi
    
    echo $line  
    
    ## DOWNLOAD READS AND MERGE MULTI-LANE FASTQS ##
    
    # R script to test for + merge technical replicates
    # Don't forget this bit:
    # chmod +x Code/techReps.R
    if [ -z $SYNID ]; then 
      if [ ! -f Data/Raw_Reads/$line"_1.fastq" ] ; then
        techReps=$(Rscript $SCRIPT_DIR/techReps.R $line $RUN_INFO)
        if [ $techReps != "no" ]; then
          if [ $techReps == "skip" ]; then
            echo "Already merged siblings ... skipping"
            continue
          else
            echo "Technical replicates detected -- downloading and merging ..."
            # Create temporary download dir
            mkdir Data/tmp/toMerge
            # Download all the SRA accessions for files to be merged
            while read file
            do
              if [ $file != "V1" ]; then
                # Download file
                echo $file
                parallel-fastq-dump -t $THREADS -s $file --split-files -O Data/tmp/toMerge --tmpdir Data/tmp
                #fastq-dump -O Data/tmp/toMerge --split-files $file
                # Cat first mate/SE reads
                cat Data/tmp/toMerge/$file"_1.fastq" >> Data/Raw_Reads/$line"_1.fastq"
                # Check to see if 2nd mate -- then merge if true
                if [ -f Data/tmp/toMerge/$file"_2.fastq" ]; then
                  cat Data/tmp/toMerge/$file"_2.fastq" >> Data/Raw_Reads/$line"_2.fastq"
                fi
              fi
            done < Data/tmp/sraTempTable.txt     
            wait
            if [ -f Data/tmp/sraTempTable.txt ]; then
              rm Data/tmp/sraTempTable.txt
            fi
            rm -rf Data/tmp/toMerge
          fi
        else
          echo "No technical replicates detected -- grabbing fastq reads from SRA ..."
          if [ ! -f Data/Raw_Reads/$line"_1.fastq" ]; then
            parallel-fastq-dump -t $THREADS -s $line --split-files -O Data/Raw_Reads --tmpdir Data/tmp
            #fastq-dump -O Data/Raw_Reads --split-files $line
          fi
        fi
      else
        echo "WARNING: "$line"_1.fastq exists ... skipping this sample ... "
        continue
      fi
    else 
      if [ $line == "synID" ]; then
        continue
      fi
      synapse login -u $USERR -p $PASS --rememberMe
      mkdir Data/Raw_Reads/synDownloadTmp
      echo $fileType
      if [ $fileType == "fastq" ]; then
        echo "FASTQ file input ... "
        if [ -z "$synapseMergeFile" ]; then
          echo
          echo "ERROR: File type is fastq, but no synapseMergeFile is provided. This is required to handle mate pairs, file renaming, and technical replicates. The synapseMergeFile is a TSV in which the first column contains the fastq file names and the second contains corresponding sample names, patient IDs, etc, to which the file belongs. For example:" 
          echo
          echo "GHX9293.1.fastq.gz  patient0098_TCX"
          echo "GHX9293.2.fastq.gz  patient0098_TCX"
          echo
          echo "or... in the case of technical replicates:"
          echo
          echo "AGTGCA_np099848_GTCACT_01_01.fastq  20092_G"
          echo "AGTGCA_np099848_GTCACT_02_01.fastq  20092_G"
          echo "AGTGCA_np099848_GTCACT_01_02.fastq  20092_G"
          echo "AGTGCA_np099848_GTCACT_02_02.fastq  20092_G"
          echo
          exit 1
        fi
        
        echo $line
        echo "Downloading fastq files and merging any technical replicates ... "
        techReps=$(Rscript $SCRIPT_DIR/techReps_Synapse.R $line $synapseMergeFile) # Checks for pre-existing files internally
        echo
        echo $techReps
        echo
        
        if [ "$techReps" != "no" ]; then
          if [ "$techReps" == "skip" ]; then
            echo "Already merged siblings ... skipping"
            continue
          else
            synapseName=$(echo "$techReps")
            echo $synapseName
            echo "DONE"
          fi
        else
          echo "WARNING: Could not locate synapse ID in provided synapseMergeFile -- skipping"
          continue            
        fi
        
        rm -rf Data/Raw_Reads/synDownloadTmp
        
      elif [ $fileType == "bam" ]; then
        echo "BAM file input ... "
        synapse get $line --downloadLocation Data/Raw_Reads/synDownloadTmp/
        synapseName=$(ls Data/Raw_Reads/synDownloadTmp/)
        filename=$(basename -- "$synapseName")
        extension="${filename##*.}"
        echo $synapseName
        synapseName=$(basename $synapseName .bam)
        echo $synapseName
        if [ ! -f Data/Raw_Reads/$synapseName"_1.fastq" ]; then 
          echo "Checking if paired or single end ... "
          PETEST=$(samtools view -c -f 1 Data/Raw_Reads/synDownloadTmp/$synapseName.bam)
          COMP=2000
          if [ "$PETEST" -gt "$COMP" ]; then
            echo "Read is paired end!"
            mkdir Data/Raw_Reads/bamSortTmp
            echo "Sorting by read name ... "
            samtools sort -n -@ $THREADS -o Data/Raw_Reads/bamSortTmp/$synapseName.bam Data/Raw_Reads/synDownloadTmp/$synapseName.bam
            echo "DONE!"
            echo "Converting to fastq ..."
            bamToFastq -i Data/Raw_Reads/bamSortTmp/$synapseName.bam -fq Data/Raw_Reads/$synapseName"_1.fastq" -fq2 Data/Raw_Reads/$synapseName"_2.fastq" &>/dev/null 
            echo "DONE"
            echo "Removing old files ...  "
            rm -rf Data/Raw_Reads/synDownloadTmp
            rm -rf Data/Raw_Reads/bamSortTmp
            echo "DONE"        
          else
            echo "Reads is single end!"
            echo "Converting to fastq ..."
            bamToFastq -i Data/Raw_Reads/synDownloadTmp/$synapseName.bam -fq Data/Raw_Reads/$synapseName"_1.fastq" &>/dev/null 
            echo "DONE"
            echo "Removing old files ... "
            rm -rf Data/Raw_Reads/synDownloadTmp
            echo "DONE"        
          fi
        fi
      fi
      
      line=$synapseName
      echo $line      
      
    fi
    
    
    ## MAIN CODE ##
    
    # Testing single-end vs paired-end
    if [ -f Data/Raw_Reads/$line"_2.fastq" ]; then
      echo Paired End
      
      # Fastp
      if [ ! -z "$FP" ]; then
        echo "Running FASTP on reads ... "
        mv Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_1.fq"
        mv Data/Raw_Reads/$line"_2.fastq" Data/Raw_Reads/$line"_2.fq"
        fastp -i Data/Raw_Reads/$line"_1.fq" -o Data/Raw_Reads/$line"_1.fastq" -I Data/Raw_Reads/$line"_2.fq" -O Data/Raw_Reads/$line"_2.fastq" -h Data/QC/HTML/$line.html -j Data/QC/JSON/$line.json -w $THREADS
        rm Data/Raw_Reads/$line"_1.fq"
        rm Data/Raw_Reads/$line"_2.fq"
        echo "DONE"
      fi
      
      if echo $TESTS | grep -q 's'; then
        ## SALMON CODE ##
        echo "SALMON!"
        # Salmon quant -- for DGE and DTU
        salmon quant -i $GENOME_DIR/Salmon_Transcripts_Index -l A -1 Data/Raw_Reads/$line"_1.fastq" -2 Data/Raw_Reads/$line"_2.fastq" --validateMappings -o Results/Salmon.out/$line -p $THREADS --gcBias 
      fi
      
      if echo $TESTS | grep -q 't'; then
        ### TE COUNT CODE ###
        echo "TE COUNT!"
        # STAR  for TEcount
        mkdir Data/Bam_Files/TE_Bams/$line
        STAR --winAnchorMultimapNmax 100 --outFilterMultimapNmax 100 --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_2.fastq" --outFileNamePrefix Data/Bam_Files/TE_Bams/$line/Result 
        samtools view -b -@ $THREADS -o Data/Bam_Files/TE_Bams/$line/$line.bam Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        
        # R Script to get strandedness info
        # Don't forget this bit:
        # chmod +x Code/getStrandedInfo.R
        strand=$($SCRIPT_DIR/getStrandednessInfo.R $line)
        
        # Needs python2 for this
        source ~/miniconda3/etc/profile.d/conda.sh      
        conda activate $CONDAENV
        # TEcount
        TEcount --verbose 3 --stranded $strand --GTF $GENOME_DIR/Assembly_Files/Genes.gtf --TE $GENOME_DIR/Assembly_Files/TE.gtf -b Data/Bam_Files/TE_Bams/$line/$line.bam --project Results/TEcount.out/$line
        # deactivate environment
        conda deactivate
      
        # Remove old files
        rm Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        rm Data/Bam_Files/TE_Bams/$line/$line.bam
      fi
      
      if echo $TESTS | grep -q 'f'; then
        ## STAR FUSION CODE ##
        echo "STAR FUSION!"
        # Need to increase number of allowed threads or this will crash
        ulimit -n 10000
        if [ ! -z $STARENV ]; then
          echo "Activating conda 2.7.0 environment."
          conda activate $STARENV
        fi
        # Star fusion main command
        STAR-Fusion --left_fq Data/Raw_Reads/$line"_1.fastq" --right_fq Data/Raw_Reads/$line"_2.fastq" --genome_lib_dir $GENOME_DIR/ctat_genome_lib_build_dir/ --CPU $THREADS --output_dir Results/STAR-Fusion.out/$line --examine_coding_effect --FusionInspector inspect --FusionInspector validate --extract_fusion_reads
        echo "DONE"
        # Remove large old files
        echo "Cleaning up fusion files ... "
        find Results/STAR-Fusion.out/$line -type f -size +1G -exec rm -rf {} \;
        echo "DONE"
        if [ ! -z $STARENV ]; then
          conda deactivate
        fi
      fi
      
      if echo $TESTS | grep -q 'S'; then
        ### Splicing Bams CODE ###
        echo "SPLICING STAR!"
        # This code generates Bams for Splicing, QoRTS, and Leafcutter
        mkdir Data/Bam_Files/Splicing_Bams/$line
        # STAR for Splicing
        STAR --outSAMstrandField intronMotif --twopassMode Basic --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_2.fastq" --outFileNamePrefix Data/Bam_Files/Splicing_Bams/$line/Result
        
        # Sort output sam and convert to bam + index
        samtools view -b -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
        samtools sort -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam 
        # Index it both ways just incase...
        samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.bai
        samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam 
        
        # Remove old files 
        rm Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
        rm Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam
      fi
      
      rm Data/Raw_Reads/$line"_1.fastq"
      rm Data/Raw_Reads/$line"_2.fastq"
      
    else
      
      ## SINGLE END READ CODE ##
      echo Single End
      
      # Fastp
      if [ ! -z "$FP" ]; then
        echo "Running FASTP on reads ... "
        mv Data/Raw_Reads/$line"_1.fastq" Data/Raw_Reads/$line"_1.fq"
        fastp -i Data/Raw_Reads/$line"_1.fq" -o Data/Raw_Reads/$line"_1.fastq" -h Data/QC/HTML/$line.html -j Data/QC/JSON/$line.json -w $THREADS
        rm Data/Raw_Reads/$line"_1.fq"
        echo "DONE"
      fi
      
      if echo $TESTS | grep -q 's'; then
        ## SALMON CODE ##
        echo "SALMON!"
        # Salmon quant -- for DGE and DTU
        salmon quant -i $GENOME_DIR/Salmon_Transcripts_Index -l A -r Data/Raw_Reads/$line"_1.fastq" --validateMappings -o Results/Salmon.out/$line -p $THREADS --gcBias 
      fi
      
      if echo $TESTS | grep -q 't'; then      
        ### TE COUNT CODE ###
        echo "TE COUNT!"
        # STAR  for TEcount
        mkdir Data/Bam_Files/TE_Bams/$line
        STAR --winAnchorMultimapNmax 100 --outFilterMultimapNmax 100 --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" --outFileNamePrefix Data/Bam_Files/TE_Bams/$line/Result 
        samtools view -b -@ $THREADS -o Data/Bam_Files/TE_Bams/$line/$line.bam Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        
        # R Script to get strandedness info
        # Don't forget this bit:
        # chmod +x Code/getStrandedInfo.R
        strand=$($SCRIPT_DIR/getStrandednessInfo.R $line)
        
        # Needs python2 for this
        source ~/miniconda3/etc/profile.d/conda.sh
        conda activate $CONDAENV
        # TEcount
        TEcount --verbose 3 --stranded $strand --GTF $GENOME_DIR/Assembly_Files/Genes.gtf --TE $GENOME_DIR/Assembly_Files/TE.gtf -b Data/Bam_Files/TE_Bams/$line/$line.bam --project Results/TEcount.out/$line
        # Deactivate it
        conda deactivate
        
        # Remove old files
        rm Data/Bam_Files/TE_Bams/$line/ResultAligned.out.sam
        rm Data/Bam_Files/TE_Bams/$line/$line.bam
        
      fi
      
      if echo $TESTS | grep -q 'f'; then
        if [ ! -z "$FSF" ]; then
          ## STAR FUSION CODE ##
          echo "STAR FUSION!"
          # Need to increase number of allowed threads or this will crash
          ulimit -n 10000
          # Star fusion main command
          STAR-Fusion --left_fq Data/Raw_Reads/$line"_1.fastq" --genome_lib_dir $GENOME_DIR/ctat_genome_lib_build_dir/ --CPU $THREADS --output_dir Results/STAR-Fusion.out/$line --examine_coding_effect --FusionInspector inspect --FusionInspector validate --extract_fusion_reads
          echo "DONE"
          # Remove large old files
          echo "Cleaning up fusion files ... "
          find Results/STAR-Fusion.out/$line -type f -size +1G -exec rm -rf {} \;
          echo "DONE"
        else
          echo WARNING: STAR Fusion not run on single-end data. You can override this behavior by adding --force_fusionSE option.
        fi
      fi
      
      if echo $TESTS | grep -q 'S'; then
        if [ ! -z "$FSS" ]; then
          ### Splicing Bams CODE ###
          echo "SPLICING STAR!"
          # This code generates Bams for Splicing, QoRTS, and Leafcutter
          mkdir Data/Bam_Files/Splicing_Bams/$line
          # STAR for Splicing
          STAR --outSAMstrandField intronMotif --twopassMode Basic --genomeDir $GENOME_DIR/STAR_Genome_Index --runThreadN $THREADS --readFilesIn Data/Raw_Reads/$line"_1.fastq" --outFileNamePrefix Data/Bam_Files/Splicing_Bams/$line/Result
          
          # Sort output sam and convert to bam + index
          samtools view -b -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
          samtools sort -@ $THREADS -o Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam 
          # Index it both ways just incase...
          samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam Data/Bam_Files/Splicing_Bams/$line/$line.bai
          samtools index Data/Bam_Files/Splicing_Bams/$line/$line.bam 
          
          # Remove old files 
          rm Data/Bam_Files/Splicing_Bams/$line/ResultAligned.out.sam
          rm Data/Bam_Files/Splicing_Bams/$line/$line.raw.bam

        else
          echo WARNING: Splicing STAR not run on single-end data. You can override this behavior by adding --force_spliceSE option.
        fi
      fi
      rm Data/Raw_Reads/$line"_1.fastq"
    fi
    
  done < Code/Accession_List.txt
  wait
  
  echo "$(date "+%m%d%Y %T") : Done"
  
) |& tee $LOGFILE 


